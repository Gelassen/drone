# import signal, sys
# import numpy as np
# import cv2
# from aruco_detector import (
#     ArUcoDetector,
#     AdvancedArUcoDetector,
#     VideoProcessor
# )

# main.py
import signal
import sys
import numpy as np
import cv2
from new_aruco_detector import (
    AruCoDetector, 
    DetectionStrategy, 
    VideoProcessor
)

def get_improved_camera_calibration():
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Å —É—á–µ—Ç–æ–º –¥–∏—Å—Ç–æ—Ä—Å–∏–π"""
    camera_matrix = np.array([[920, 0, 640],
                              [0, 920, 360], 
                              [0, 0, 1]], dtype=np.float32)
    
    # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–∏—Å—Ç–æ—Ä—Å–∏–∏
    dist_coeffs = np.array([-0.2, 0.1, 0.001, 0.001, 0.0], dtype=np.float32)
    
    return camera_matrix, dist_coeffs

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    
    ARUCO_DICTS = [
        cv2.aruco.DICT_4X4_50,
        cv2.aruco.DICT_4X4_100,
        cv2.aruco.DICT_5X5_50,
    ]
    
    camera_matrix, dist_coeffs = get_improved_camera_calibration()
    
    def handle_exit(signum=None, frame=None):
        print("\nüõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
        cv2.destroyAllWindows()
        sys.exit(0)
    
    signal.signal(signal.SIGINT, handle_exit)
    
    video_processor = None
    try:
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        strategies = [
            DetectionStrategy.STANDARD,
            DetectionStrategy.MULTI_PASS, 
            DetectionStrategy.REGION_AWARE,
            DetectionStrategy.ADAPTIVE
        ]
        
        video_processor = VideoProcessor("../../assets/ar_test_video.MOV")
        
        for strategy in strategies:
            print(f"\nüîç –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é: {strategy.value}")
            
            aruco_detector = AruCoDetector(
                ARUCO_DICTS, camera_matrix, dist_coeffs, strategy=strategy
            )
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –≤–∏–¥–µ–æ
            video_processor.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤
            for i in range(30):  # 30 –∫–∞–¥—Ä–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞
                ret, frame = video_processor.read_frame()
                if not ret:
                    break
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞
                detected = aruco_detector.process(frame)
                aruco_detector.postProcess(frame)
                
                cv2.imshow("ArUco Pose Estimation", frame)
                
                if cv2.waitKey(10) & 0xFF == 27:
                    handle_exit()
                    return
                    
            cv2.waitKey(1000)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏
                
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    finally:
        if video_processor:
            video_processor.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()

# def get_improved_camera_calibration():
#     """–£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Å —É—á–µ—Ç–æ–º –¥–∏—Å—Ç–æ—Ä—Å–∏–π"""
#     camera_matrix = np.array([[920, 0, 640],
#                               [0, 920, 360], 
#                               [0, 0, 1]], dtype=np.float32)
    
#     # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–∏—Å—Ç–æ—Ä—Å–∏–∏
#     dist_coeffs = np.array([-0.2, 0.1, 0.001, 0.001, 0.0], dtype=np.float32)
    
#     return camera_matrix, dist_coeffs

# def main():
#     """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    
#     # --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
#     ARUCO_DICTS = [
#         cv2.aruco.DICT_4X4_50,
#         cv2.aruco.DICT_4X4_100,
#         cv2.aruco.DICT_5X5_50,
#     ]
    
#     # –ü—Å–µ–≤–¥–æ–∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –∫–∞–º–µ—Ä—ã
#     # camera_matrix = np.array([[920, 0, 640],
#     #                           [0, 920, 360],
#     #                           [0, 0, 1]], dtype=np.float32)
#     # dist_coeffs = np.zeros((5, 1))

#     camera_matrix, dist_coeffs = get_improved_camera_calibration()
    
#     # --- –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è ---
#     def handle_exit(signum=None, frame=None):
#         print("\nüõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
#         cv2.destroyAllWindows()
#         sys.exit(0)
    
#     signal.signal(signal.SIGINT, handle_exit)
    
#     try:
#         # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
#         video_processor = VideoProcessor("../../assets/ar_test_video.MOV")
#         aruco_detector = AdvancedArUcoDetector(ARUCO_DICTS, camera_matrix, dist_coeffs)
        
#         # --- –ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ ---
#         while True:
#             ret, frame = video_processor.read_frame()
#             if not ret:
#                 print("‚ö†Ô∏è –ö–æ–Ω–µ—Ü –≤–∏–¥–µ–æ –∏–ª–∏ –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è.")
#                 break
            
#             # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
#             processed_frame = aruco_detector.preProcess(frame)
            
#             # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
#             detected = aruco_detector.process_advanced(frame)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π frame –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
            
#             # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
#             aruco_detector.postProcess(frame)
            
#             # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
#             cv2.imshow("ArUco Pose Estimation", frame)
            
#             # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π –≤—ã—Ö–æ–¥–∞
#             key = cv2.waitKey(10) & 0xFF
#             if key == 27 or cv2.getWindowProperty("ArUco Pose Estimation", cv2.WND_PROP_VISIBLE) < 1:
#                 handle_exit()
                
#     except Exception as e:
#         print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
#         handle_exit()


# if __name__ == "__main__":
#     main()